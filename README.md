# üöÄ Ingest√£o de Dados - Zebrinha Azul

Este projeto faz a ingest√£o de dados de clima e tr√¢nsito, processando-os em duas camadas: Bronze e Silver.

# üß† Contexto

A Zebrinha Azul √© uma startup inovadora que se destaca no mercado por sua expertise em lidar com dados de clima e tr√°fego. A empresa fornece solu√ß√µes avan√ßadas para otimizar opera√ß√µes log√≠sticas e proporcionar relat√≥rios para clientes de diversos setores. A atual miss√£o √© desenvolver um sistema robusto e escal√°vel para integrar, processar e analisar os dados de clima e tr√°fego que a Zebrinha Azul coleta.

## üìò Tabelas

Os scripts desenvolvidos entregam as seguintes tabelas:

| Schema | Tabela | Descri√ß√£o |
|--------|--------|-----------|
| bronze | city_information | Informa√ß√µes principais de cada cidade, extra√≠das da API |
| bronze | temperatures_information | Informa√ß√µes sobre temperatura de cada cidade, extra√≠das da API |
| bronze | weather_of_the_day | Informa√ß√µes sobre o clima do dia, extra√≠das da API |
| bronze | wind_information | Informa√ß√µes sobre o vento de cada cidade, extra√≠das da API |
| bronze | traffic_direction | Informa√ß√µes sobre a dire√ß√£o do tr√¢nsito, contendo colunas como **star_address**, **end_address**, **duration_hours**, **id_city_origem** e **id_city_destino** |
| silver | city_information | Dados tratados e formatados corretamente, como **horas** e **ref** |
| silver | temperatures_information | Dados tratados e formatados corretamente, como **temp_celsius**, **temp_fahrenheit** e **dt_ingestao** |
| silver | weather_of_the_day | Dados tratados e formatados corretamente, como **data** |
| silver | wind_information | Dados tratados e formatados corretamente, como **km/h** e **mph** |

### Camada Bronze

A camada Bronze √© a inicial de ingest√£o de dados, onde todas as informa√ß√µes das APIs s√£o armazenadas com pouca ou nenhuma transforma√ß√£o, mantendo valores brutos.

### Camada Silver

Na camada Silver, os dados s√£o limpos, normalizados e transformados para uma estrutura mais compreens√≠vel. Colunas adicionais s√£o inclu√≠das para auxiliar o time t√©cnico e fornecer valor para √°reas de neg√≥cio. Esta camada permite consultas mais eficientes para an√°lise de dados.

## ‚öôÔ∏è Como Rodar o Pipeline

Todo o processo √© executado em um √∫nico script. Abaixo est√° a descri√ß√£o da estrutura de pastas do pipeline de ingest√£o de dados:

- **src/features**: Cont√©m todos os scripts para gerar tabelas nas camadas Bronze e Silver.
- **src/pipeline.py**: Executa o pipeline e faz a ingest√£o de dados no SQL Server.
- **src/utils**: Diret√≥rio contendo scripts auxiliares para o desenvolvimento do c√≥digo.

### Executando o Pipeline

Para rodar o pipeline, execute o seguinte comando:

```bash
python pipeline.py
```

### Passando Argumento de Tamanho Amostral

Na hora de executar o pipeline, passamos o argumento `tamanho_amostral`, que define a quantidade de dados que queremos extrair da API de cidades. Como este √© um teste, escolhemos 5 amostras. Esse par√¢metro permite limitar o n√∫mero de cidades processadas, facilitando testes e depura√ß√£o do c√≥digo.

### Configura√ß√µes

#### Criando Ambiente Virtual

```bash
python -m venv venv

# Linux
source venv/bin/activate

# Windows
.\venv\Scripts\activate
```

#### Vari√°veis de Ambiente

Crie um arquivo `.env` e adicione as seguintes informa√ß√µes:

```env
API_TRANSITO_KEY="SUA_CHAVE"
API_CLIMA_KEY="SUA_CHAVE"
SERVER="SERVIDOR_BANCO"
```

## Diagrama Relacional

Para acessar o diagrama relacional, veja a imagem abaixo:

<img src="./src/images/diagrama.png" alt="Diagrama Relacional">


---

Desenvolvedor: Arthur Fillipe Oliveira Rocha